### Objective & Goals of Research
In this project, we aim to improve on Open-World Segmentation (OWS) on Cityscapes dataset and BDDAnomaally dataset.

We are reproducing and extending the work of _[Sodano et al.](https://arxiv.org/pdf/2403.07532)_.

Repo structure:
```
ðŸ“¦ 
â”œâ”€Â .gitignore
â”œâ”€Â README.md
â”œâ”€Â fyp
â”‚Â Â â”œâ”€Â .gitignore
â”‚Â Â â”œâ”€Â .vscode
â”‚Â Â â”‚Â Â â””â”€Â launch.json
â”‚Â Â â”œâ”€Â README.md
â”‚Â Â â”œâ”€Â mavs.pickle
â”‚Â Â â”œâ”€Â overfitall.sh
â”‚Â Â â”œâ”€Â proprocessing_unknown_known.py
â”‚Â Â â”œâ”€Â requirements.yml
â”‚Â Â â”œâ”€Â scripts
â”‚Â Â â”‚Â Â â””â”€Â run_all.pbs
â”‚Â Â â”œâ”€Â src
â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
â”‚Â Â â”‚Â Â â”œâ”€Â args.py
â”‚Â Â â”‚Â Â â”œâ”€Â build_model.py
â”‚Â Â â”‚Â Â â”œâ”€Â datasets
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â cityscapes
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â README.md
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â cityscapes.py
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â prepare_dataset.py
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â pytorch_dataset.py
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â requirements.txt
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â weighting_linear_1+16_val.pickle
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â weighting_linear_1+17_val.pickle
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â weighting_linear_1+19_train.pickle
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â weighting_linear_1+19_val.pickle
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â weighting_linear_1+19_valid.pickle
â”‚Â Â â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â weighting_median_frequency_1+19_train.pickle
â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â dataset_base.py
â”‚Â Â â”‚Â Â â”œâ”€Â losses
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â ce_loss.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â contrastive_loss.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â dice_loss.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â focal_loss.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â objectosphere_loss.py
â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â ow_loss.py
â”‚Â Â â”‚Â Â â”œâ”€Â models_v2
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â context_modules.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â decoder.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â model.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â model_utils.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â neck.py
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â resnet.py
â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â tru_for_decoder.py
â”‚Â Â â”‚Â Â â”œâ”€Â prepare_data.py
â”‚Â Â â”‚Â Â â”œâ”€Â preprocessing.py
â”‚Â Â â”‚Â Â â””â”€Â utils.py
â”‚Â Â â”œâ”€Â start.sh
â”‚Â Â â”œâ”€Â train.py
â”‚Â Â â””â”€Â vars.pickle
â”œâ”€Â scripts
â”‚Â Â â”œâ”€Â downlioad_cityscapes.sh
â”‚Â Â â”œâ”€Â run.sh
â”‚Â Â â””â”€Â run_all.pbs
â””â”€Â vars.pickle
```

### Original Model
We implement the Encoder-Decoder architecture defined in the ContMAV paper. We initially use ResNet34 and train our model for 500 epochs using a learning rate of 0.004, as in the paper, on CityScapes Dataset.
The cityscapes data is a large dataset of street-level images with pixel-level annotations for 19 classes. The dataset is split into training, validation, and test sets.

### Tru For
We aim to improve the performance of the model by using a different architecture. We add an additional decoder to the model from [Guillaro et al.](https://arxiv.org/pdf/2212.10957) to the model and combine the logits from both decoders.

### Different Loss Functions
We also try using different loss functions:
- Focal Loss
- Focal Loss with Dice Loss
- Infonce Loss for Ananomaly Detection

### Infonce Loss
We separate crops from the image, extracting the known and unknown classes. We then use the Infonce loss to train the model to distinguish between the known and unknown classes. The Infonce loss is defined as:
```python
def infonce_loss(known, unknown):
    known = F.normalize(known, dim=1)
    unknown = F.normalize(unknown, dim=1)
    logits = torch.mm(known, unknown.t())
    labels = torch.arange(logits.size(0)).to(logits.device)
    loss = F.cross_entropy(logits, labels)
    return loss
```
This method allows for the model to learn to distinguish between the known and unknown classes, improving the performance of the model on the OWS task. Especially since the samples of unknown classes are usually not balanced.

### Synco
From the synco paper, we utilise the idea of generating hard negatives from the known classes. 

Which is better?:
- We use the known classes to generate hard negatives for the unknown classes. This allows the model to learn to distinguish between the known and unknown classes, improving the performance of the model on the OWS task.
- We also use the unknown classes to generate hard negatives for the known classes. This allows the model to learn to distinguish between the known and unknown classes, improving the performance of the model on the OWS task.

